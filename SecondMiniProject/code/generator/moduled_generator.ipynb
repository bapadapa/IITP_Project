{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 생성한 모듈 경로\r\n",
    "import generate_mod\r\n",
    "# 그 외의 모듈들\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "#파일 가져오기\r\n",
    "# Json 파일 및 소설 가져오기 읽기\r\n",
    "config = generate_mod.read_json()\r\n",
    "text = generate_mod.read_all_text(config,config['genres'][1])\r\n",
    "\r\n",
    "# 인덱싱 사전 생성 및 모든 텍스트 맵핑시킴\r\n",
    "vocab, char2idx, idx2char , text_as_int  = generate_mod.indexing(text)\r\n",
    " \r\n",
    "# training Sample/Target 생성\r\n",
    "# numpy -> tensor 형변환이라고 생각하는게 편함\r\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\r\n",
    "\r\n",
    "# 청크파일 만들기 (즉 훈련 셈플등을 구하기)\r\n",
    "sequences = char_dataset.batch(config['seq_length']+1 , drop_remainder = True)\r\n",
    "dataset = sequences.map(generate_mod.split_input_target)\r\n",
    "\r\n",
    "# 읽어온 텍스트 길이로 버퍼 크기 선정\r\n",
    "Buffer_size = len(text_as_int) * 2\r\n",
    "\r\n",
    "# BUFFER_SIZE개로 이루어진 버퍼로 임의의 샘플을 뽑은 후 BATCH_SIZE로 분할한다.\r\n",
    "dataset = dataset.shuffle(Buffer_size).batch(config['batch_size'], drop_remainder= True)\r\n",
    "\r\n",
    "# 모델생성\r\n",
    "model = generate_mod.model_learning(\r\n",
    "    config = config,\r\n",
    "    vocab = vocab,\r\n",
    "    dataset= dataset,\r\n",
    "    genre_Index = 1\r\n",
    "    )\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 267s 211ms/step - loss: 3.2308\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.6501\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.5016\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 247s 195ms/step - loss: 2.4127\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.3503\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.3030\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 2.2647\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 2.2326\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 246s 194ms/step - loss: 2.2052\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.1811\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 246s 195ms/step - loss: 2.1592\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 2.1394\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 2.1216\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 248s 196ms/step - loss: 2.1045\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 247s 195ms/step - loss: 2.0890\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 246s 194ms/step - loss: 2.0745\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 2.0609\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 242s 192ms/step - loss: 2.0480\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 246s 194ms/step - loss: 2.0354\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 245s 193ms/step - loss: 2.0240\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 245s 193ms/step - loss: 2.0133\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 245s 194ms/step - loss: 2.0028\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.9930\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 245s 194ms/step - loss: 1.9832\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 246s 194ms/step - loss: 1.9739\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9658\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9572\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.9494\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9420\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9348\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.9285\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9217\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.9158\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.9099\n",
      "Epoch 35/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.9042\n",
      "Epoch 36/100\n",
      "1266/1266 [==============================] - 245s 193ms/step - loss: 1.8989\n",
      "Epoch 37/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8939\n",
      "Epoch 38/100\n",
      "1266/1266 [==============================] - 245s 194ms/step - loss: 1.8890\n",
      "Epoch 39/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8844\n",
      "Epoch 40/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.8797\n",
      "Epoch 41/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8761\n",
      "Epoch 42/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8721\n",
      "Epoch 43/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8681\n",
      "Epoch 44/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8646\n",
      "Epoch 45/100\n",
      "1266/1266 [==============================] - 245s 194ms/step - loss: 1.8612\n",
      "Epoch 46/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8580\n",
      "Epoch 47/100\n",
      "1266/1266 [==============================] - 246s 195ms/step - loss: 1.8550\n",
      "Epoch 48/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8524\n",
      "Epoch 49/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8496\n",
      "Epoch 50/100\n",
      "1266/1266 [==============================] - 246s 195ms/step - loss: 1.8471\n",
      "Epoch 51/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8443\n",
      "Epoch 52/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8419\n",
      "Epoch 53/100\n",
      "1266/1266 [==============================] - 246s 194ms/step - loss: 1.8397\n",
      "Epoch 54/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8379\n",
      "Epoch 55/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8355\n",
      "Epoch 56/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8340\n",
      "Epoch 57/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8320\n",
      "Epoch 58/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8299\n",
      "Epoch 59/100\n",
      "1266/1266 [==============================] - 247s 195ms/step - loss: 1.8289\n",
      "Epoch 60/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8274\n",
      "Epoch 61/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8258\n",
      "Epoch 62/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8245\n",
      "Epoch 63/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8229\n",
      "Epoch 64/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8219\n",
      "Epoch 65/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8208\n",
      "Epoch 66/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.8196\n",
      "Epoch 67/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8184\n",
      "Epoch 68/100\n",
      "1266/1266 [==============================] - 244s 193ms/step - loss: 1.8175\n",
      "Epoch 69/100\n",
      "1266/1266 [==============================] - 242s 192ms/step - loss: 1.8163\n",
      "Epoch 70/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8149\n",
      "Epoch 71/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8144\n",
      "Epoch 72/100\n",
      "1266/1266 [==============================] - 243s 192ms/step - loss: 1.8136\n",
      "Epoch 73/100\n",
      "1266/1266 [==============================] - 242s 191ms/step - loss: 1.8128\n",
      "Epoch 74/100\n",
      "1266/1266 [==============================] - 242s 192ms/step - loss: 1.8122\n",
      "Epoch 75/100\n",
      " 291/1266 [=====>........................] - ETA: 3:04 - loss: 1.7864"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 생성한 모듈 경로\r\n",
    "import generate_mod\r\n",
    "# 그 외의 모듈들\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "generate_mod.generate_text(\r\n",
    "    model_index = 1, \r\n",
    "    start_string = '사건이 ',\r\n",
    "    num_generate = 1000,\r\n",
    "    temperature = 0.7\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "a6701f6db813f1c844b12c4e46b29afdab8244af650e803d413695b0e6cec516"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}