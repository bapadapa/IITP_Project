{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 수집 및 전처리"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 병합\r\n",
    "\r\n",
    "## 데이터셋 목록 (출처, 데이터명, 컬럼명, 데이터시작지점, 최종지점, 수집주기 등) \r\n",
    "\r\n",
    "|활용|파일명|데이터|시작 시점|최종지점|수집주기|기준일|\r\n",
    "|-|-|-|-|-|-|-|\r\n",
    "|범죄 발생 건수 집계|crime_location.csv|2010|2020|1년|2021|\r\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|income_level_by_region.csv|2000|2019|1년|2021|\r\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|economic_activity_by_region.csv|2000|2020|1년|2021|\r\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|olice_officer_num_by_region.csv|2009|2017|1년|2021|\r\n",
    "|인구적 요소|population_by_region.csv|1992|2020|1년|2021|\r\n",
    "|인구적 요소|population_movement_by_region.csv|2001|2020|1년|2021|\r\n",
    "|인구적 요소|외국인_거주자.csv|2003|2020|1년|2021|\r\n",
    "|<font color = 'gray'>공간적 요소 집계<font/>|local_data.csv|2000|2020|1년|2021|\r\n",
    "|<font color = 'gray'>공간적 요소 집계<font/>|universities_by_region.csv|2003|2020|1년|2021|\r\n",
    "|기타 요인|시도_산업_조직형태별_사업체수_종사자수.csv|2000|2019|1년|2021|\r\n",
    "|기타 요인|number_of_psychotropic_drug_requests_by_region.csv|2010|2020|1년|2021|\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 필요 라이브러리, 데이터 불러오기 및 경로 설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "source": [
    "import pandas as pd\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import font_manager,rc\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.preprocessing import minmax_scale\r\n",
    "from pyarrow import csv\r\n",
    "import json\r\n",
    "import collections\r\n",
    "import cx_Oracle\r\n",
    "import warnings\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "data_path ='../data/'\r\n",
    "# Json 파일 읽어오기\r\n",
    "def read_json(jsonPath ,mod = 'r',encoding ='utf-8'):\r\n",
    "    with open(jsonPath, mod, encoding = encoding) as common:\r\n",
    "        config = json.load(common)\r\n",
    "    return config\r\n",
    "config = read_json(data_path + \"json/config.json\")\r\n",
    "\r\n",
    "# Orcale 연동\r\n",
    "CONN_INFO = {\r\n",
    "        'NAME': 'XEPDB1',\r\n",
    "        'USER': 'iitp',\r\n",
    "        'PASSWORD': 'iitp',\r\n",
    "        'HOST': '172.16.5.231',\r\n",
    "        'PORT': '11521',\r\n",
    "}\r\n",
    "CONN_STR = '{USER}/{PASSWORD}@{HOST}:{PORT}/{NAME}'.format(**CONN_INFO)\r\n",
    "conn = cx_Oracle.connect(CONN_STR)\r\n",
    "cursor = conn.cursor()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def transColName(cols):\r\n",
    "    cols = cols.replace(' (%)', '')\r\n",
    "    cols = cols.replace(' (명)', '')\r\n",
    "    cols = cols.replace('[명]', '')\r\n",
    "    cols = cols.replace('[백분율]', '')\r\n",
    "    cols = cols.replace(')', '')\r\n",
    "    cols = cols.replace('(', '_')\r\n",
    "    cols = cols.replace(' ', '_')\r\n",
    "    cols = cols.replace('1', '')\r\n",
    "    return cols \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 공간적 요소 병합"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "local_path = config['data_path']+ 'csv/localData/cleaned/'\r\n",
    "\r\n",
    "flag = True\r\n",
    "for fileN in os.listdir(local_path):\r\n",
    "    readed_file = csv.read_csv(local_path +fileN).to_pandas()\r\n",
    "    readed_file = readed_file.dropna()\r\n",
    "    tmp = pd.DataFrame(columns=['시도','년도',readed_file.columns[-1]])\r\n",
    "    for city in readed_file.시도.unique():\r\n",
    "        for year in readed_file[readed_file.시도 == city].연도.unique():\r\n",
    "            tmp= tmp.append(pd.Series(\r\n",
    "                [\r\n",
    "                    city,\r\n",
    "                    year,\r\n",
    "                    readed_file[((readed_file.시도 == city) & (readed_file.연도== year))].iloc[:,-1].sum()\r\n",
    "                    ] , index = tmp.columns)\r\n",
    "                ,ignore_index= True)\r\n",
    "    if flag :\r\n",
    "        result = tmp.copy()\r\n",
    "        flag = False\r\n",
    "        continue\r\n",
    "    \r\n",
    "    result = pd.merge(result, tmp, left_on=['시도','년도'], right_on=['시도','년도'], how='left')\r\n",
    "result = result.fillna(0) \r\n",
    "# 병합할 칼럼들 ( 유사 의미를 가지고 있는 칼럼 병합)\r\n",
    "restrant = ['일반음식점','휴게음식점','관광식당']\r\n",
    "bar = ['단란주점', '유흥주점', '외국인전용유흥음식점업']\r\n",
    "\r\n",
    "result['음식점'] =result[restrant].sum(axis = 1)\r\n",
    "result['유흥가'] = result[bar].sum(axis = 1)\r\n",
    "#병합된 칼럼 제거\r\n",
    "result = result.drop(restrant+bar,axis= 1)\r\n",
    "\r\n",
    "# 단위개 개수이기 때문에 소수점 제거\r\n",
    "result.iloc[:,1:] = result.iloc[:,1:].astype(int)\r\n",
    "\r\n",
    "result.to_csv(config['data_path']+ 'csv/semicleaned/local.csv',encoding='utf-8-sig',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 범죄 발생지 병합"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 범죄 발생지 병합\r\n",
    "merged_df = pd.DataFrame()\r\n",
    "flag = True\r\n",
    "for fp in os.listdir(config['data_path']+ 'csv/crime_location'):     \r\n",
    "    merged_csv = csv.read_csv(config['data_path']+ 'csv/crime_location/'+fp).to_pandas()\r\n",
    "    merged_csv['시도'] = merged_csv['시도'].map(config['cities_mapping'])\r\n",
    "    if flag :\r\n",
    "        merged_df = merged_csv\r\n",
    "        flag = False\r\n",
    "    else:\r\n",
    "        merged_df = pd.concat([merged_df,merged_csv], ignore_index=True)\r\n",
    "\r\n",
    "# 데이터 병합\r\n",
    "merged_df['폭행'] = merged_df['폭행'].add(merged_df['상해'])\r\n",
    "merged_df['공갈'] = merged_df['공갈'].add(merged_df['협박'])\r\n",
    "merged_df = merged_df.drop(['상해','협박'],axis=1)\r\n",
    "merged_df = merged_df.rename(columns={'폭행':'폭행및상해','공갈':'공갈및협박'})\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# -로 저장되어있는 값들 NA값으로 변경\r\n",
    "def cleaning(x) :\r\n",
    "  if str(x).find(\"-\") != -1 :\r\n",
    "    return str(x).replace(\"-\",'')\r\n",
    "  return x\r\n",
    "\r\n",
    "for colName in merged_df.columns:\r\n",
    "    merged_df[colName] = merged_df[colName].apply(cleaning)\r\n",
    "\r\n",
    "# result.drop_duplicates()\r\n",
    "merged_df.drop_duplicates().to_csv(config['data_path']+ 'csv/semicleaned/crime_location.csv',encoding='utf-8-sig',index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모든 데이터 병합\r\n",
    "\r\n",
    "### 제거한 데이터\r\n",
    "\r\n",
    "- 실질적 일반 사람에게 피해가 없는 `범죄 파라미터` 제거\r\n",
    "- 특정 대학의 수는 의미가 없다 판단하여 대학교 총계를 제외한 `대학수 제거`\r\n",
    "- 성비를 이용한 인구수는 기타 데이터와 연계시 데이터 부족에 의하여 제거 `성별로 나누어진 데이터 제거`\r\n",
    "- 시도간 전입,전출 칼럼을 보유하면 기다 전입 `전출 데이터`가 불필요하다 판단이 되어 제거"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 모든 데이터 병합\r\n",
    "result = pd.DataFrame()\r\n",
    "flag = True\r\n",
    "for fp in os.listdir(config['data_path']+ 'csv/semicleaned'):\r\n",
    "    \r\n",
    "    merged_csv = csv.read_csv(config['data_path']+ 'csv/semicleaned/'+fp).to_pandas()\r\n",
    "    merged_csv['시도'] = merged_csv['시도'].map(config['cities_mapping'])\r\n",
    "    if flag :\r\n",
    "        result = merged_csv\r\n",
    "        flag = False\r\n",
    "    else:\r\n",
    "        result = pd.merge(\r\n",
    "            result, merged_csv,\r\n",
    "            left_on=['년도','시도'],\r\n",
    "            right_on=['년도','시도'],\r\n",
    "            how='left')\r\n",
    "# 만약 중복되어 삽입된 행이 있다면 제거\r\n",
    "result.drop_duplicates()\r\n",
    "# 불필요하다 판단된 칼럼 제거\r\n",
    "result = result.drop(config['dropCols'],axis = 1).drop_duplicates()\r\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv',encoding='utf-8-sig',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  상관계수 값이 0.7이상인 칼럼만 추출 후 상위 5개 칼럼 추출"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\r\n",
    "df = df[(df.년도 >= 2002)&(df.년도 <= 2019)]\r\n",
    "crime_name = df.columns[2:15] \r\n",
    "independent_val = df.columns[15:] \r\n",
    "\r\n",
    "\r\n",
    "df['범죄소계'] = df[crime_name].sum(axis = 1)\r\n",
    "crime_name = crime_name.to_list()+['범죄소계']\r\n",
    "\r\n",
    "corr_df = pd.DataFrame(columns=['시도','범죄','칼럼리스트'])\r\n",
    "\r\n",
    "for city in df['시도'].unique():\r\n",
    "    tmp_df = df[df.시도 == city]\r\n",
    "    for crime_ in crime_name:\r\n",
    "        tmp_list = []\r\n",
    "        for key,value in  (tmp_df[[crime_] + independent_val.to_list()].corr().iloc[0,1:].abs() >= 0.7).to_dict().items():\r\n",
    "            if value == True :\r\n",
    "                tmp_list += [transColName(key)]\r\n",
    "        corr_df = corr_df.append(\r\n",
    "            pd.Series(\r\n",
    "                [city,\r\n",
    "                crime_,\r\n",
    "                tmp_list],\r\n",
    "                index = corr_df.columns\r\n",
    "            ),\r\n",
    "            ignore_index=True\r\n",
    "        )\r\n",
    "\r\n",
    "corr_result = pd.DataFrame(columns=['범죄','칼럼리스트'])\r\n",
    "\r\n",
    "for c_name in corr_df.범죄.unique():\r\n",
    "    corr_df[corr_df.범죄 == c_name]\r\n",
    "    tmp_list = []\r\n",
    "    for i in corr_df[corr_df.범죄 == c_name].칼럼리스트:\r\n",
    "        tmp_list += i\r\n",
    "\r\n",
    "    corr_Top_Five = sorted(collections.Counter(tmp_list).items(), key=lambda x: x[1])[-5:]\r\n",
    "    t_list = []\r\n",
    "    for Top_Five_Name in corr_Top_Five:\r\n",
    "        t_list+= [Top_Five_Name[0]]\r\n",
    "    # print(c_name,t_list)\r\n",
    "    corr_result = corr_result.append(\r\n",
    "        pd.Series(\r\n",
    "            [c_name,\r\n",
    "            t_list],\r\n",
    "            index = corr_result.columns\r\n",
    "        ),\r\n",
    "        ignore_index=True\r\n",
    "    )\r\n",
    "corr_result.to_csv(config['data_path']+ 'csv/cleaned/Top_Five_Cols.csv',encoding = 'utf-8-sig',index =False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 범죄별 인덱싱"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "merged_df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\r\n",
    "# 범죄 소계 데이터가 2002 ~ 2019까지 있기 떄문에 그 이외의 데이터 제거\r\n",
    "merged_df = merged_df[(merged_df.년도 >=2002)& (merged_df.년도 <=2019)]\r\n",
    "\r\n",
    "\r\n",
    "yearNcities_name= merged_df.columns[:2].to_list()\r\n",
    "crimes = merged_df.columns[2:15].to_list()\r\n",
    "indiventent_val_name = merged_df.columns[15:].to_list()\r\n",
    "idx = 0\r\n",
    "# 범죄 소계로 초기화\r\n",
    "\r\n",
    "crime_Specification=pd.DataFrame([[idx,'범죄소계']],columns = ['idx','범죄명'])\r\n",
    "\r\n",
    "result = merged_df[yearNcities_name + indiventent_val_name]\r\n",
    "result['범죄수'] = merged_df[crimes].sum(axis = 1)\r\n",
    "result['범죄종류'] = idx\r\n",
    "result = result[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\r\n",
    "idx+=1\r\n",
    "\r\n",
    "for crime_name in  crimes:\r\n",
    "    for_Merge = merged_df[yearNcities_name + [crime_name] + indiventent_val_name]\r\n",
    "    for_Merge = for_Merge.rename(columns={crime_name:'범죄수'})\r\n",
    "    for_Merge['범죄종류'] = idx   \r\n",
    "\r\n",
    "    crime_Specification = crime_Specification.append(pd.Series(\r\n",
    "            [\r\n",
    "                idx,\r\n",
    "                crime_name\r\n",
    "            ] , index = crime_Specification.columns)\r\n",
    "            ,ignore_index= True)\r\n",
    "    result =pd.concat(\r\n",
    "        [\r\n",
    "        result,\r\n",
    "        for_Merge[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\r\n",
    "        ],\r\n",
    "        ignore_index=True)\r\n",
    "    idx+=1\r\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/crime_indexed.csv',encoding='utf-8-sig',index=False)\r\n",
    "crime_Specification.to_csv(config['data_path']+ 'csv/cleaned/crime_Specification.csv',encoding='utf-8-sig',index=False)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-149-a5d3c08c388e>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['범죄수'] = merged_df[crimes].sum(axis = 1)\n",
      "<ipython-input-149-a5d3c08c388e>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['범죄종류'] = idx\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 예측한 데이터프레임에 기존 데이터 삽입"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "source": [
    "def df_round(df , cols = ['이혼율','고용률','실업률','한국인_남녀비율','한국인_인구밀도','경찰청_인원_명당_담당_인구']):\r\n",
    "    count_col_name= df.columns.to_list()\r\n",
    "    for colN in cols:\r\n",
    "        count_col_name.remove(colN)\r\n",
    "    for colN in count_col_name:\r\n",
    "        df[colN] = df[colN].round()\r\n",
    "    df['시도'] = df['시도'].astype(int)\r\n",
    "    df['년도'] = df['년도'].astype(int)\r\n",
    "    return df\r\n",
    "def alter_pridict(df,raw_df):\r\n",
    "    for colName in raw_df.columns[2:]:\r\n",
    "        for _,items in raw_df[raw_df[colName].isna() !=True][['시도','년도',colName]].iterrows():\r\n",
    "            df.loc[\r\n",
    "            (df.시도==items[0]) & (df.년도==items[1]),colName\r\n",
    "            ] = items[2]\r\n",
    "    return df   \r\n",
    "\r\n",
    "sido_code = pd.read_sql(\"select * from sido_code\",con=conn) \r\n",
    "sido_code['CODE'] = sido_code['CODE'].astype(int)\r\n",
    "sejong_code = sido_code[sido_code.KOR_NAME == '세종'].iloc[0]['CODE']\r\n",
    "\r\n",
    "indi_val = df_round(pd.read_sql(\"select * from independent_val\",con=conn).astype(float) )\r\n",
    "indi_val = indi_val[indi_val.시도 != sejong_code]\r\n",
    "\r\n",
    "indi_zero = df_round(pd.read_sql(\"select * from independent_zero\",con=conn).astype(float) )\r\n",
    "indi_zero = indi_zero[indi_zero.시도 != sejong_code]\r\n",
    "\r\n",
    "indi_mean = df_round(pd.read_sql(\"select * from independent_mean\",con=conn).astype(float) )\r\n",
    "indi_mean = indi_mean[indi_mean.시도 != sejong_code]\r\n",
    "\r\n",
    "raw_02_19 = indi_val[(indi_val.년도 >= 2002)].sort_values(['시도' ,'년도'])\r\n",
    "zero_02_19 = indi_zero[(indi_zero.년도 >= 2002)].sort_values(['시도' ,'년도'])\r\n",
    "mean_02_19 = indi_mean[(indi_mean.년도 >= 2002)].sort_values(['시도' ,'년도'])\r\n",
    " \r\n",
    "alter_pridict(zero_02_19,raw_02_19).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_rawData.csv',encoding='utf-8-sig',index=False)\r\n",
    "alter_pridict(mean_02_19,raw_02_19).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_rawData.csv',encoding='utf-8-sig',index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 결측값 체우기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "source": [
    "crime_df  = csv.read_csv('../data/csv/cleaned/crime_merged.csv').to_pandas()\r\n",
    "crime_df = crime_df[crime_df.시도 != '세종']\r\n",
    "indi_df = crime_df.drop(crime_df.columns[2:15],axis = 1 )\r\n",
    "\r\n",
    "def predict_(df_,sido,years):\r\n",
    "    df_.sort_values(by = '년도',inplace= True)    \r\n",
    "    x = df_.년도\r\n",
    "    y = df_.iloc[:,2:]\r\n",
    "    # 모델 생성\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(x.values.reshape(-1,1),y)\r\n",
    "    # 예측\r\n",
    "    result = model.predict(np.array(years).reshape(-1,1))\r\n",
    "    return pd.concat(\r\n",
    "        [\r\n",
    "            pd.DataFrame({'시도': [sido], '년도' : [years]}),\r\n",
    "            pd.DataFrame(result, columns=indi_df.columns[2:])\r\n",
    "            ],axis=1)\r\n",
    "\r\n",
    "def predict_regression(df_,sido,years):\r\n",
    "    df_.sort_values(by = '년도',inplace= True)    \r\n",
    "    x = df_.년도\r\n",
    "    y = df_.iloc[:,2:]\r\n",
    "    # 모델 생성\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(x.values.reshape(-1,1),y)\r\n",
    "    # 예측\r\n",
    "    result = model.predict(years.reshape(-1,1))\r\n",
    "\r\n",
    "    year_sido=  pd.DataFrame(np.arange(2000,2020),columns=['년도'])\r\n",
    "    year_sido['시도'] = sido    \r\n",
    "    return pd.concat(\r\n",
    "            [\r\n",
    "                year_sido[year_sido.columns[::-1]],pd.DataFrame(result, columns=indi_df.columns[2:])\r\n",
    "                ],axis=1)\r\n",
    "\r\n",
    "# result = pd.DataFrame(columns = indi_df.columns)\r\n",
    "# 결측값 0으로 삽입\r\n",
    "result = pd.DataFrame(columns = indi_df.columns)\r\n",
    "for sido in indi_df.시도.unique():\r\n",
    "    for_predict = indi_df[indi_df.시도 == sido].fillna(0)\r\n",
    "    for year in range(2021,2031):\r\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\r\n",
    "    result= result.append(for_predict)\r\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict.csv',encoding='utf-8-sig',index=False)\r\n",
    "\r\n",
    "# 결측값 평균값으로 삽입\r\n",
    "result = pd.DataFrame(columns = indi_df.columns)\r\n",
    "for sido in indi_df.시도.unique():\r\n",
    "    for_predict = indi_df[indi_df.시도 == sido].fillna(indi_df.where(pd.notnull(indi_df),indi_df.mean(),axis=  'columns'))\r\n",
    "    for year in range(2021,2031):\r\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\r\n",
    "    result= result.append(for_predict)\r\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict.csv',encoding='utf-8-sig',index=False)\r\n",
    "\r\n",
    "# 결측값 회기분석으로 삽입\r\n",
    "result = pd.DataFrame(columns = indi_df.columns)\r\n",
    "for sido in indi_df.시도.unique():\r\n",
    "    # 선형회기로 데이터프레임 생성 후 결측값 대체\r\n",
    "    for_predict = alter_pridict(\r\n",
    "                        predict_regression(\r\n",
    "                            indi_df[indi_df.시도 == sido].dropna() ,sido, np.arange(2000,2020)\r\n",
    "                            ) , indi_df[indi_df.시도 == sido])\r\n",
    "    for year in range(2021,2031):\r\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\r\n",
    "    result= result.append(for_predict)\r\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv',encoding='utf-8-sig',index=False)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터들 인구수로 나누어 정규화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "source": [
    "def div_by_pop(df):    \r\n",
    "    percent_cols = [\r\n",
    "    '이혼율','고용률 (%)','실업률 (%)','1인당 지역내총생산', '1인당 지역총소득', '1인당 개인소득', '1인당 민간소비','경찰청 인원 1명당 담당 인구','한국인(남녀비율[백분율])','한국인(인구밀도)'\r\n",
    "    ]\r\n",
    "    percent_cols = list(map(transColName,percent_cols))\r\n",
    "\r\n",
    "    other_cols = df.columns.drop(percent_cols)\r\n",
    "    population = df[transColName('총인구수 (명)')]\r\n",
    "    other_cols.drop(transColName('한국인(총인구수[명])'))\r\n",
    "    div_by_population = df[other_cols].iloc[:,2:].div(population,axis = 0).iloc[:,:-1]\r\n",
    "    df[div_by_population.columns] = div_by_population\r\n",
    "    \r\n",
    "    drop_list= ['한국인(총인구수[명])' ,'총인구수 (명)','경찰청 인원 1명당 담당 인구']\r\n",
    "    drop_list= list(map(transColName,drop_list))\r\n",
    "    df.drop(drop_list,axis =1,inplace=True)\r\n",
    "    return df\r\n",
    "\r\n",
    "    \r\n",
    "mean_ = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_rawData.csv').to_pandas()\r\n",
    "mean_div = div_by_pop(mean_.copy())\r\n",
    "pd.concat( [mean_div, mean_.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_div_pop.csv' , encoding='utf-8-sig',index = False)\r\n",
    "\r\n",
    "zero_ = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_rawData.csv').to_pandas()\r\n",
    "zero_div = div_by_pop(zero_.copy())\r\n",
    "pd.concat( [zero_div, zero_.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_div_pop.csv' , encoding='utf-8-sig',index = False)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "##############\r\n",
    "\r\n",
    "zero_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict.csv').to_pandas()\r\n",
    "zero_predict.columns = percent_cols = list(map(transColName,zero_predict.columns))\r\n",
    "zero_predict_div = div_by_pop(zero_predict.copy())\r\n",
    "pd.concat( [zero_predict_div, zero_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\r\n",
    "\r\n",
    "mean_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict.csv').to_pandas()\r\n",
    "mean_predict.columns = percent_cols = list(map(transColName,mean_predict.columns))\r\n",
    "mean_predict_div = div_by_pop(mean_predict.copy())\r\n",
    "pd.concat( [mean_predict_div, mean_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\r\n",
    "\r\n",
    "regression_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv').to_pandas()\r\n",
    "regression_predict.columns = percent_cols = list(map(transColName,regression_predict.columns))\r\n",
    "regression_predict_div = div_by_pop(regression_predict.copy())\r\n",
    "pd.concat( [regression_predict_div, regression_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('iitp_keras': conda)"
  },
  "interpreter": {
   "hash": "c4409229afdb447283b42faeee1bfbefcd5f4f3487cbb679b593e138b99762ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}