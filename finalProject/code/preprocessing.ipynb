{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 병합\n",
    "\n",
    "## 데이터셋 목록 (출처, 데이터명, 컬럼명, 데이터시작지점, 최종지점, 수집주기 등) \n",
    "\n",
    "|활용|파일명|데이터|시작 시점|최종지점|수집주기|기준일|\n",
    "|-|-|-|-|-|-|-|\n",
    "|범죄 발생 건수 집계|crime_location.csv|2010|2020|1년|2021|\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|income_level_by_region.csv|2000|2019|1년|2021|\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|economic_activity_by_region.csv|2000|2020|1년|2021|\n",
    "|<font color = 'gray'>사회적 요소 집계 <font/>|olice_officer_num_by_region.csv|2009|2017|1년|2021|\n",
    "|인구적 요소|population_by_region.csv|1992|2020|1년|2021|\n",
    "|인구적 요소|population_movement_by_region.csv|2001|2020|1년|2021|\n",
    "|인구적 요소|외국인_거주자.csv|2003|2020|1년|2021|\n",
    "|<font color = 'gray'>공간적 요소 집계<font/>|local_data.csv|2000|2020|1년|2021|\n",
    "|<font color = 'gray'>공간적 요소 집계<font/>|universities_by_region.csv|2003|2020|1년|2021|\n",
    "|기타 요인|시도_산업_조직형태별_사업체수_종사자수.csv|2000|2019|1년|2021|\n",
    "|기타 요인|number_of_psychotropic_drug_requests_by_region.csv|2010|2020|1년|2021|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리, 데이터 불러오기 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager,rc\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from pyarrow import csv\n",
    "import json\n",
    "import collections\n",
    "import cx_Oracle\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='../data/'\n",
    "# Json 파일 읽어오기\n",
    "def read_json(jsonPath ,mod = 'r',encoding ='utf-8'):\n",
    "    with open(jsonPath, mod, encoding = encoding) as common:\n",
    "        config = json.load(common)\n",
    "    return config\n",
    "config = read_json(data_path + \"json/config.json\")\n",
    "\n",
    "# Orcale 연동\n",
    "CONN_INFO = {\n",
    "        'NAME': 'XEPDB1',\n",
    "        'USER': 'iitp',\n",
    "        'PASSWORD': 'iitp',\n",
    "        'HOST': '172.16.5.231',\n",
    "        'PORT': '11521',\n",
    "}\n",
    "CONN_STR = '{USER}/{PASSWORD}@{HOST}:{PORT}/{NAME}'.format(**CONN_INFO)\n",
    "conn = cx_Oracle.connect(CONN_STR)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "def transColName(cols):\n",
    "    cols = cols.replace(' (%)', '')\n",
    "    cols = cols.replace(' (명)', '')\n",
    "    cols = cols.replace('[명]', '')\n",
    "    cols = cols.replace('[백분율]', '')\n",
    "    cols = cols.replace(')', '')\n",
    "    cols = cols.replace('(', '_')\n",
    "    cols = cols.replace(' ', '_')\n",
    "    cols = cols.replace('1', '')\n",
    "    return cols \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공간적 요소 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = config['data_path']+ 'csv/localData/cleaned/'\n",
    "\n",
    "flag = True\n",
    "for fileN in os.listdir(local_path):\n",
    "    readed_file = csv.read_csv(local_path +fileN).to_pandas()\n",
    "    readed_file = readed_file.dropna()\n",
    "    tmp = pd.DataFrame(columns=['시도','년도',readed_file.columns[-1]])\n",
    "    for city in readed_file.시도.unique():\n",
    "        for year in readed_file[readed_file.시도 == city].연도.unique():\n",
    "            tmp= tmp.append(pd.Series(\n",
    "                [\n",
    "                    city,\n",
    "                    year,\n",
    "                    readed_file[((readed_file.시도 == city) & (readed_file.연도== year))].iloc[:,-1].sum()\n",
    "                    ] , index = tmp.columns)\n",
    "                ,ignore_index= True)\n",
    "    if flag :\n",
    "        result = tmp.copy()\n",
    "        flag = False\n",
    "        continue\n",
    "    \n",
    "    result = pd.merge(result, tmp, left_on=['시도','년도'], right_on=['시도','년도'], how='left')\n",
    "result = result.fillna(0) \n",
    "# 병합할 칼럼들 ( 유사 의미를 가지고 있는 칼럼 병합)\n",
    "restrant = ['일반음식점','휴게음식점','관광식당']\n",
    "bar = ['단란주점', '유흥주점', '외국인전용유흥음식점업']\n",
    "\n",
    "result['음식점'] =result[restrant].sum(axis = 1)\n",
    "result['유흥가'] = result[bar].sum(axis = 1)\n",
    "#병합된 칼럼 제거\n",
    "result = result.drop(restrant+bar,axis= 1)\n",
    "\n",
    "# 단위개 개수이기 때문에 소수점 제거\n",
    "result.iloc[:,1:] = result.iloc[:,1:].astype(int)\n",
    "\n",
    "result.to_csv(config['data_path']+ 'csv/semicleaned/local.csv',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범죄 발생지 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범죄 발생지 병합\n",
    "merged_df = pd.DataFrame()\n",
    "flag = True\n",
    "for fp in os.listdir(config['data_path']+ 'csv/crime_location'):     \n",
    "    merged_csv = csv.read_csv(config['data_path']+ 'csv/crime_location/'+fp).to_pandas()\n",
    "    merged_csv['시도'] = merged_csv['시도'].map(config['cities_mapping'])\n",
    "    if flag :\n",
    "        merged_df = merged_csv\n",
    "        flag = False\n",
    "    else:\n",
    "        merged_df = pd.concat([merged_df,merged_csv], ignore_index=True)\n",
    "\n",
    "# 데이터 병합\n",
    "merged_df['폭행'] = merged_df['폭행'].add(merged_df['상해'])\n",
    "merged_df['공갈'] = merged_df['공갈'].add(merged_df['협박'])\n",
    "merged_df = merged_df.drop(['상해','협박'],axis=1)\n",
    "merged_df = merged_df.rename(columns={'폭행':'폭행및상해','공갈':'공갈및협박'})\n",
    "\n",
    "\n",
    "\n",
    "# -로 저장되어있는 값들 NA값으로 변경\n",
    "def cleaning(x) :\n",
    "  if str(x).find(\"-\") != -1 :\n",
    "    return str(x).replace(\"-\",'')\n",
    "  return x\n",
    "\n",
    "for colName in merged_df.columns:\n",
    "    merged_df[colName] = merged_df[colName].apply(cleaning)\n",
    "\n",
    "# result.drop_duplicates()\n",
    "merged_df.drop_duplicates().to_csv(config['data_path']+ 'csv/semicleaned/crime_location.csv',encoding='utf-8-sig',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 데이터 병합\n",
    "\n",
    "### 제거한 데이터\n",
    "\n",
    "- 실질적 일반 사람에게 피해가 없는 `범죄 파라미터` 제거\n",
    "- 특정 대학의 수는 의미가 없다 판단하여 대학교 총계를 제외한 `대학수 제거`\n",
    "- 성비를 이용한 인구수는 기타 데이터와 연계시 데이터 부족에 의하여 제거 `성별로 나누어진 데이터 제거`\n",
    "- 시도간 전입,전출 칼럼을 보유하면 기다 전입 `전출 데이터`가 불필요하다 판단이 되어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터 병합\n",
    "result = pd.DataFrame()\n",
    "flag = True\n",
    "for fp in os.listdir(config['data_path']+ 'csv/semicleaned'):\n",
    "    \n",
    "    merged_csv = csv.read_csv(config['data_path']+ 'csv/semicleaned/'+fp).to_pandas()\n",
    "    merged_csv['시도'] = merged_csv['시도'].map(config['cities_mapping'])\n",
    "    if flag :\n",
    "        result = merged_csv\n",
    "        flag = False\n",
    "    else:\n",
    "        result = pd.merge(\n",
    "            result, merged_csv,\n",
    "            left_on=['년도','시도'],\n",
    "            right_on=['년도','시도'],\n",
    "            how='left')\n",
    "# 만약 중복되어 삽입된 행이 있다면 제거\n",
    "result.drop_duplicates()\n",
    "# 불필요하다 판단된 칼럼 제거\n",
    "result = result.drop(config['dropCols'],axis = 1).drop_duplicates()\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측처리별 상관계수 값이 0.7이상인 칼럼만 추출 후 상위 5개 칼럼 추출\n",
    "\n",
    "1. 0 으로 체움\n",
    "1. mean값으로 체움\n",
    "1. 선형회기를 이용하여 체움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\n",
    "df = df[(df.년도 >= 2002)&(df.년도 <= 2019)&(df.시도 != '세종')]\n",
    "crime_val = df.iloc[:,:15]\n",
    "crime_val['범죄소계'] =  crime_val.iloc[:,2:].sum(axis = 1)\n",
    "crime_name = crime_val.columns[2:]\n",
    "\n",
    "# indi_val = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv').to_pandas()\n",
    "# indi_val = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict.csv').to_pandas()\n",
    "indi_val = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict.csv').to_pandas()\n",
    "indi_val = indi_val[(indi_val.년도 >= 2002)&(indi_val.년도 <= 2019)&(indi_val.시도 != '세종')]\n",
    "independent_val = indi_val.columns[2:]\n",
    "\n",
    "merged_val = pd.merge(crime_val, indi_val, left_on=['시도','년도'], right_on=['시도','년도'], how='left')\n",
    "# merged_val.columns\n",
    "\n",
    "corr_df = pd.DataFrame(columns=['시도','범죄','칼럼리스트'])\n",
    "\n",
    "for city in merged_val['시도'].unique():\n",
    "    tmp_df = merged_val[merged_val.시도 == city]\n",
    "    for crime_ in crime_name:\n",
    "        tmp_list = []\n",
    "        for key,value in  (tmp_df[[crime_] + independent_val.to_list()].corr().iloc[0,1:].abs() >= 0.7).to_dict().items():\n",
    "            if value == True :\n",
    "                tmp_list += [transColName(key)]\n",
    "        corr_df = corr_df.append(\n",
    "            pd.Series(\n",
    "                [city,\n",
    "                crime_,\n",
    "                tmp_list],\n",
    "                index = corr_df.columns\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "corr_df\n",
    "\n",
    "corr_result = pd.DataFrame(columns=['범죄','칼럼리스트'])\n",
    "\n",
    "for c_name in corr_df.범죄.unique():\n",
    "    corr_df[corr_df.범죄 == c_name]\n",
    "    tmp_list = []\n",
    "    for i in corr_df[corr_df.범죄 == c_name].칼럼리스트:\n",
    "        tmp_list += i\n",
    "\n",
    "    corr_Top_Five = sorted(collections.Counter(tmp_list).items(), key=lambda x: x[1])[-5:]\n",
    "    t_list = []\n",
    "    for Top_Five_Name in corr_Top_Five:\n",
    "        t_list+= [Top_Five_Name[0]]\n",
    "        \n",
    "    corr_result = corr_result.append(\n",
    "        pd.Series(\n",
    "            [c_name,\n",
    "            t_list],\n",
    "            index = corr_result.columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "corr_result.to_csv(config['data_path']+ 'csv/cleaned/Top_Five_zero_Cols.csv',encoding = 'utf-8-sig',index =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\n",
    "df = df[(df.년도 >= 2002)&(df.년도 <= 2019)]\n",
    "crime_name = df.columns[2:15] \n",
    "independent_val = df.columns[15:] \n",
    "\n",
    "\n",
    "df['범죄소계'] = df[crime_name].sum(axis = 1)\n",
    "crime_name = crime_name.to_list()+['범죄소계']\n",
    "\n",
    "corr_df = pd.DataFrame(columns=['시도','범죄','칼럼리스트'])\n",
    "\n",
    "for city in df['시도'].unique():\n",
    "    tmp_df = df[df.시도 == city]\n",
    "    for crime_ in crime_name:\n",
    "        tmp_list = []\n",
    "        for key,value in  (tmp_df[[crime_] + independent_val.to_list()].corr().iloc[0,1:].abs() >= 0.7).to_dict().items():\n",
    "            if value == True :\n",
    "                tmp_list += [transColName(key)]\n",
    "        corr_df = corr_df.append(\n",
    "            pd.Series(\n",
    "                [city,\n",
    "                crime_,\n",
    "                tmp_list],\n",
    "                index = corr_df.columns\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "corr_result = pd.DataFrame(columns=['범죄','칼럼리스트'])\n",
    "\n",
    "for c_name in corr_df.범죄.unique():\n",
    "    corr_df[corr_df.범죄 == c_name]\n",
    "    tmp_list = []\n",
    "    for i in corr_df[corr_df.범죄 == c_name].칼럼리스트:\n",
    "        tmp_list += i\n",
    "\n",
    "    corr_Top_Five = sorted(collections.Counter(tmp_list).items(), key=lambda x: x[1])[-5:]\n",
    "    t_list = []\n",
    "    for Top_Five_Name in corr_Top_Five:\n",
    "        t_list+= [Top_Five_Name[0]]\n",
    "    # print(c_name,t_list)\n",
    "    corr_result = corr_result.append(\n",
    "        pd.Series(\n",
    "            [c_name,\n",
    "            t_list],\n",
    "            index = corr_result.columns\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "corr_result.to_csv(config['data_path']+ 'csv/cleaned/Top_Five_Cols.csv',encoding = 'utf-8-sig',index =False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범죄별 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-a5d3c08c388e>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['범죄수'] = merged_df[crimes].sum(axis = 1)\n",
      "<ipython-input-149-a5d3c08c388e>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['범죄종류'] = idx\n"
     ]
    }
   ],
   "source": [
    "merged_df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\n",
    "# 범죄 소계 데이터가 2002 ~ 2019까지 있기 떄문에 그 이외의 데이터 제거\n",
    "merged_df = merged_df[(merged_df.년도 >=2002)& (merged_df.년도 <=2019)]\n",
    "\n",
    "\n",
    "yearNcities_name= merged_df.columns[:2].to_list()\n",
    "crimes = merged_df.columns[2:15].to_list()\n",
    "indiventent_val_name = merged_df.columns[15:].to_list()\n",
    "idx = 0\n",
    "# 범죄 소계로 초기화\n",
    "\n",
    "crime_Specification=pd.DataFrame([[idx,'범죄소계']],columns = ['idx','범죄명'])\n",
    "\n",
    "result = merged_df[yearNcities_name + indiventent_val_name]\n",
    "result['범죄수'] = merged_df[crimes].sum(axis = 1)\n",
    "result['범죄종류'] = idx\n",
    "result = result[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\n",
    "idx+=1\n",
    "\n",
    "for crime_name in  crimes:\n",
    "    for_Merge = merged_df[yearNcities_name + [crime_name] + indiventent_val_name]\n",
    "    for_Merge = for_Merge.rename(columns={crime_name:'범죄수'})\n",
    "    for_Merge['범죄종류'] = idx   \n",
    "\n",
    "    crime_Specification = crime_Specification.append(pd.Series(\n",
    "            [\n",
    "                idx,\n",
    "                crime_name\n",
    "            ] , index = crime_Specification.columns)\n",
    "            ,ignore_index= True)\n",
    "    result =pd.concat(\n",
    "        [\n",
    "        result,\n",
    "        for_Merge[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\n",
    "        ],\n",
    "        ignore_index=True)\n",
    "    idx+=1\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/crime_indexed.csv',encoding='utf-8-sig',index=False)\n",
    "crime_Specification.to_csv(config['data_path']+ 'csv/cleaned/crime_Specification.csv',encoding='utf-8-sig',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측한 데이터프레임에 기존 데이터 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_round(df , cols = ['이혼율','고용률','실업률','한국인_남녀비율','한국인_인구밀도','경찰청_인원_명당_담당_인구']):\n",
    "    count_col_name= df.columns.to_list()\n",
    "    for colN in cols:\n",
    "        count_col_name.remove(colN)\n",
    "    for colN in count_col_name:\n",
    "        df[colN] = df[colN].round()\n",
    "    df['시도'] = df['시도'].astype(int)\n",
    "    df['년도'] = df['년도'].astype(int)\n",
    "    return df\n",
    "def alter_pridict(df,raw_df):\n",
    "    for colName in raw_df.columns[2:]:\n",
    "        for _,items in raw_df[raw_df[colName].isna() !=True][['시도','년도',colName]].iterrows():\n",
    "            df.loc[\n",
    "            (df.시도==items[0]) & (df.년도==items[1]),colName\n",
    "            ] = items[2]\n",
    "    return df   \n",
    "\n",
    "sido_code = pd.read_sql(\"select * from sido_code\",con=conn) \n",
    "sido_code['CODE'] = sido_code['CODE'].astype(int)\n",
    "sejong_code = sido_code[sido_code.KOR_NAME == '세종'].iloc[0]['CODE']\n",
    "\n",
    "indi_val = df_round(pd.read_sql(\"select * from independent_val\",con=conn).astype(float) )\n",
    "indi_val = indi_val[indi_val.시도 != sejong_code]\n",
    "\n",
    "indi_zero = df_round(pd.read_sql(\"select * from independent_zero\",con=conn).astype(float) )\n",
    "indi_zero = indi_zero[indi_zero.시도 != sejong_code]\n",
    "\n",
    "indi_mean = df_round(pd.read_sql(\"select * from independent_mean\",con=conn).astype(float) )\n",
    "indi_mean = indi_mean[indi_mean.시도 != sejong_code]\n",
    "\n",
    "raw_02_19 = indi_val[(indi_val.년도 >= 2002)].sort_values(['시도' ,'년도'])\n",
    "zero_02_19 = indi_zero[(indi_zero.년도 >= 2002)].sort_values(['시도' ,'년도'])\n",
    "mean_02_19 = indi_mean[(indi_mean.년도 >= 2002)].sort_values(['시도' ,'년도'])\n",
    " \n",
    "alter_pridict(zero_02_19,raw_02_19).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_rawData.csv',encoding='utf-8-sig',index=False)\n",
    "alter_pridict(mean_02_19,raw_02_19).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_rawData.csv',encoding='utf-8-sig',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결측값 체우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df  = csv.read_csv('../data/csv/cleaned/crime_merged.csv').to_pandas()\n",
    "crime_df = crime_df[crime_df.시도 != '세종']\n",
    "indi_df = crime_df.drop(crime_df.columns[2:15],axis = 1 )\n",
    "\n",
    "def predict_(df_,sido,years):\n",
    "    df_.sort_values(by = '년도',inplace= True)    \n",
    "    x = df_.년도\n",
    "    y = df_.iloc[:,2:]\n",
    "    # 모델 생성\n",
    "    model = LinearRegression()\n",
    "    model.fit(x.values.reshape(-1,1),y)\n",
    "    # 예측\n",
    "    result = model.predict(np.array(years).reshape(-1,1))\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame({'시도': [sido], '년도' : [years]}),\n",
    "            pd.DataFrame(result, columns=indi_df.columns[2:])\n",
    "            ],axis=1)\n",
    "\n",
    "def predict_regression(df_,sido,years):\n",
    "    df_.sort_values(by = '년도',inplace= True)    \n",
    "    x = df_.년도\n",
    "    y = df_.iloc[:,2:]\n",
    "    # 모델 생성\n",
    "    model = LinearRegression()\n",
    "    model.fit(x.values.reshape(-1,1),y)\n",
    "    # 예측\n",
    "    result = model.predict(years.reshape(-1,1))\n",
    "\n",
    "    year_sido=  pd.DataFrame(np.arange(2000,2020),columns=['년도'])\n",
    "    year_sido['시도'] = sido    \n",
    "    return pd.concat(\n",
    "            [\n",
    "                year_sido[year_sido.columns[::-1]],pd.DataFrame(result, columns=indi_df.columns[2:])\n",
    "                ],axis=1)\n",
    "\n",
    "# result = pd.DataFrame(columns = indi_df.columns)\n",
    "# 결측값 0으로 삽입\n",
    "result = pd.DataFrame(columns = indi_df.columns)\n",
    "for sido in indi_df.시도.unique():\n",
    "    for_predict = indi_df[indi_df.시도 == sido].fillna(0)\n",
    "    for year in range(2021,2031):\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\n",
    "    result= result.append(for_predict)\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict.csv',encoding='utf-8-sig',index=False)\n",
    "\n",
    "# 결측값 평균값으로 삽입\n",
    "result = pd.DataFrame(columns = indi_df.columns)\n",
    "for sido in indi_df.시도.unique():\n",
    "    for_predict = indi_df[indi_df.시도 == sido].fillna(indi_df.where(pd.notnull(indi_df),indi_df.mean(),axis=  'columns'))\n",
    "    for year in range(2021,2031):\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\n",
    "    result= result.append(for_predict)\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict.csv',encoding='utf-8-sig',index=False)\n",
    "\n",
    "# 결측값 회기분석으로 삽입\n",
    "result = pd.DataFrame(columns = indi_df.columns)\n",
    "for sido in indi_df.시도.unique():\n",
    "    # 선형회기로 데이터프레임 생성 후 결측값 대체\n",
    "    for_predict = alter_pridict(\n",
    "                        predict_regression(\n",
    "                            indi_df[indi_df.시도 == sido].dropna() ,sido, np.arange(2000,2020)\n",
    "                            ) , indi_df[indi_df.시도 == sido])\n",
    "    for year in range(2021,2031):\n",
    "        for_predict = for_predict.append(predict_(for_predict,sido,year))\n",
    "    result= result.append(for_predict)\n",
    "result.to_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv',encoding='utf-8-sig',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터들 인구수로 나누어 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_by_pop(df):    \n",
    "    percent_cols = [\n",
    "    '이혼율','고용률 (%)','실업률 (%)','1인당 지역내총생산', '1인당 지역총소득', '1인당 개인소득', '1인당 민간소비','경찰청 인원 1명당 담당 인구','한국인(남녀비율[백분율])','한국인(인구밀도)'\n",
    "    ]\n",
    "    percent_cols = list(map(transColName,percent_cols)) \n",
    "\n",
    "    other_cols = df.columns.drop(percent_cols)\n",
    "    population = df[transColName('총인구수 (명)')]\n",
    "    other_cols.drop(transColName('한국인(총인구수[명])'))\n",
    "    div_by_population = df[other_cols].iloc[:,2:].div(population,axis = 0).iloc[:,:-1]\n",
    "    df[div_by_population.columns] = div_by_population\n",
    "    \n",
    "    drop_list= ['한국인(총인구수[명])' ,'총인구수 (명)','경찰청 인원 1명당 담당 인구']\n",
    "    drop_list= list(map(transColName,drop_list))\n",
    "    df.drop(drop_list,axis =1,inplace=True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "mean_ = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_rawData.csv').to_pandas()\n",
    "mean_div = div_by_pop(mean_.copy())\n",
    "pd.concat( [mean_div, mean_.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_insert_div_pop.csv' , encoding='utf-8-sig',index = False)\n",
    "\n",
    "zero_ = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_rawData.csv').to_pandas()\n",
    "zero_div = div_by_pop(zero_.copy())\n",
    "pd.concat( [zero_div, zero_.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_insert_div_pop.csv' , encoding='utf-8-sig',index = False)\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "\n",
    "zero_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict.csv').to_pandas()\n",
    "zero_predict.columns = percent_cols = list(map(transColName,zero_predict.columns))\n",
    "zero_predict_div = div_by_pop(zero_predict.copy())\n",
    "pd.concat( [zero_predict_div, zero_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/zero_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\n",
    "\n",
    "mean_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict.csv').to_pandas()\n",
    "mean_predict.columns = percent_cols = list(map(transColName,mean_predict.columns))\n",
    "mean_predict_div = div_by_pop(mean_predict.copy())\n",
    "pd.concat( [mean_predict_div, mean_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/mean_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\n",
    "\n",
    "regression_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv').to_pandas()\n",
    "regression_predict.columns = percent_cols = list(map(transColName,regression_predict.columns))\n",
    "regression_predict_div = div_by_pop(regression_predict.copy())\n",
    "pd.concat( [regression_predict_div, regression_predict.iloc[:,-1]] , axis = 1).to_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict_div_pop.csv' , encoding='utf-8-sig',index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_predict = csv.read_csv(config['data_path']+ 'csv/cleaned/independent/regression_predict.csv').to_pandas()\n",
    "regression_predict =regression_predict[(regression_predict.년도 >= 2002)&(regression_predict.년도 <= 2019)&(df.시도 != '세종')]\n",
    "df = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_merged.csv').to_pandas()\n",
    "df = df[(df.년도 >= 2002)&(df.년도 <= 2019)&(df.시도 != '세종')]\n",
    "merged = pd.merge(crime_val, regression_predict, left_on=['시도','년도'], right_on=['시도','년도'], how='right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_crime = csv.read_csv(config['data_path']+ 'csv/cleaned/crime_predicted.csv').to_pandas()\n",
    "predicted_crime['범죄소계'] = predicted_crime.iloc[:,2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = ['년도','시도','범죄코드','범죄수'])\n",
    "result_code = pd.DataFrame(columns = ['코드','범죄명'])\n",
    "for idx in range(len(predicted_crime.columns[2:])):\n",
    "    tmpCrime = predicted_crime[['년도','시도',predicted_crime.columns[2+idx]]]\n",
    "    for year in predicted_crime.년도.unique():\n",
    "        tmpYear = tmpCrime[tmpCrime.년도 == year]\n",
    "        for city in predicted_crime.시도.unique():\n",
    "            tmpCity = tmpYear[tmpYear.시도 == city]\n",
    "            result = result.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        '년도': [year],\n",
    "                        '시도': [city],\n",
    "                        '범죄코드': [idx],\n",
    "                        '범죄수': [\n",
    "                                tmpCity[predicted_crime.columns[2+idx]].values[0]\n",
    "                            ]\n",
    "                        }\n",
    "                )\n",
    "            )\n",
    "            result_code =result_code.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        '범죄코드': [idx],\n",
    "                        '범죄명': [predicted_crime.columns[2+idx]]\n",
    "                        }\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crime_Specification=pd.DataFrame([[idx,'범죄소계']],columns = ['idx','범죄명'])\n",
    "\n",
    "idx = 0\n",
    "result = merged_df[yearNcities_name + indiventent_val_name]\n",
    "result['범죄수'] = merged_df[crimes].sum(axis = 1)\n",
    "result['범죄종류'] = idx\n",
    "result = result[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\n",
    "idx+=1\n",
    "\n",
    "for crime_name in  crimes:\n",
    "    for_Merge = merged_df[yearNcities_name + [crime_name] + indiventent_val_name]\n",
    "    for_Merge = for_Merge.rename(columns={crime_name:'범죄수'})\n",
    "    for_Merge['범죄종류'] = idx   \n",
    "\n",
    "    crime_Specification = crime_Specification.append(pd.Series(\n",
    "            [\n",
    "                idx,\n",
    "                crime_name\n",
    "            ] , index = crime_Specification.columns)\n",
    "            ,ignore_index= True)\n",
    "    result =pd.concat(\n",
    "        [\n",
    "        result,\n",
    "        for_Merge[yearNcities_name + ['범죄종류','범죄수'] + indiventent_val_name]\n",
    "        ],\n",
    "        ignore_index=True)\n",
    "    idx+=1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4409229afdb447283b42faeee1bfbefcd5f4f3487cbb679b593e138b99762ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('iitp_keras': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
